{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c56e06c4-70ab-4d1b-a4ee-3e9baa95d6aa",
   "metadata": {},
   "source": [
    "# Upscaling Service\n",
    "This notebooks showcases a demo of the APEx Upscaling Service by demonstrating the capabilities of the [APEx Dispatch API](https://github.com/ESA-APEx/apex_dispatch_api). In this notebook we will perform a small upscaling exercise for one of the services in the [APEx Algoritm Services Catalogue](https://algorithm-catalogue.apex.esa.int/), specfically the [PV Farm Detection](https://algorithm-catalogue.apex.esa.int/apps/eurac_pv_farm_detection#description). We will split up an area of interest in a 20x20km grid and execute this  through this upscaling task through the APEx Dispatch API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b52c73f-779b-49c2-99bf-7ab5a9e84aa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: esa-apex-algorithms in /Users/bramjanssen/.pyenv/versions/3.10.12/lib/python3.10/site-packages (0.0.1)\n",
      "Requirement already satisfied: requests>=2.30.0 in /Users/bramjanssen/.pyenv/versions/3.10.12/lib/python3.10/site-packages (from esa-apex-algorithms) (2.32.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/bramjanssen/.pyenv/versions/3.10.12/lib/python3.10/site-packages (from requests>=2.30.0->esa-apex-algorithms) (2.3.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/bramjanssen/.pyenv/versions/3.10.12/lib/python3.10/site-packages (from requests>=2.30.0->esa-apex-algorithms) (3.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/bramjanssen/.pyenv/versions/3.10.12/lib/python3.10/site-packages (from requests>=2.30.0->esa-apex-algorithms) (2025.1.31)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/bramjanssen/.pyenv/versions/3.10.12/lib/python3.10/site-packages (from requests>=2.30.0->esa-apex-algorithms) (3.4.1)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install esa-apex-algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d99f5fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import rasterio\n",
    "import numpy as np\n",
    "import tempfile\n",
    "import asyncio\n",
    "import json\n",
    "import websockets\n",
    "import httpx\n",
    "import io\n",
    "import base64\n",
    "import time\n",
    "from ipyleaflet import ImageOverlay\n",
    "from PIL import Image\n",
    "from ipyleaflet import Map, GeoJSON, TileLayer\n",
    "from rasterio.warp import transform_bounds\n",
    "from shapely.geometry import shape\n",
    "from pyproj import Transformer\n",
    "from authlib.integrations.requests_client import OAuth2Session\n",
    "from urllib.parse import urlparse, parse_qs\n",
    "from esa_apex_toolbox.algorithms import GithubAlgorithmRepository"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fea370d-9df7-41c3-b746-ff35b5e3852c",
   "metadata": {},
   "source": [
    "## Look up the algorithm to execute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f27153c4-4f0d-4a83-a112-cc19c72ecd75",
   "metadata": {},
   "outputs": [],
   "source": [
    "repo = GithubAlgorithmRepository(\n",
    "            owner=\"ESA-APEx\",\n",
    "            repo=\"apex_algorithms\",\n",
    "            folder=\"algorithm_catalog\",\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c92aba78-41d4-4436-af8e-1cb3ade79d88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['wind_turbine',\n",
       " 'eurac_pv_farm_detection',\n",
       " 'gep_bas',\n",
       " 'gep_ost',\n",
       " 'sar_coin',\n",
       " 'snap_insar_sentinel1_iw_slc',\n",
       " 'bap_composite',\n",
       " 'biopar',\n",
       " 'fusets_mogpr',\n",
       " 'max_ndvi',\n",
       " 'max_ndvi_composite',\n",
       " 'parcel_delineation',\n",
       " 'random_forest_firemapping',\n",
       " 'sentinel1_stats',\n",
       " 'variabilitymap',\n",
       " 'worldcereal_crop_extent',\n",
       " 'worldcereal_crop_type',\n",
       " 'worldcover_statistics',\n",
       " 'worldagrocommodities']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "repo.list_algorithms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cf8a0add-e49d-4df1-9934-5e996c24b863",
   "metadata": {},
   "outputs": [],
   "source": [
    "service = repo.get_algorithm('eurac_pv_farm_detection')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ce0b51c0-5895-4454-8783-ce2d16f9252d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Algorithm(id='eurac_pv_farm_detection', title='Photovoltaic farms mapping', description='Demonstrator service for the detection of photovoltaic farms. Photovoltaic farms (PV farms) mapping is essential for establishing valid policies regarding natural resources management and clean energy. ', udp_link=UdpLink(href='https://raw.githubusercontent.com/ESA-APEx/apex_algorithms/refs/heads/main/algorithm_catalog/eurac/eurac_pv_farm_detection/openeo_udp/eurac_pv_farm_detection.json', title='openEO Process Definition'), service_links=[ServiceLink(href='https://openeofed.dataspace.copernicus.eu', title='CDSE openEO federation')], license=None, organization='Eurac Research')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "service"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2179224-deec-4005-90ad-78122871b35a",
   "metadata": {},
   "source": [
    "## Definition of parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f95065a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dispatch_api = \"localhost:8000\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c83aa9d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "spatial_extent = {\n",
    "        \"coordinates\": [\n",
    "          [\n",
    "            [\n",
    "              16.148187382518586,\n",
    "              48.33760911876428\n",
    "            ],\n",
    "            [\n",
    "              16.148187382518586,\n",
    "              48.06620807624728\n",
    "            ],\n",
    "            [\n",
    "              16.62751804693653,\n",
    "              48.06620807624728\n",
    "            ],\n",
    "            [\n",
    "              16.62751804693653,\n",
    "              48.33760911876428\n",
    "            ],\n",
    "            [\n",
    "              16.148187382518586,\n",
    "              48.33760911876428\n",
    "            ]\n",
    "          ]\n",
    "        ],\n",
    "        \"type\": \"Polygon\"\n",
    "      }\n",
    "temporal_extent = [\"2023-05-01\", \"2023-09-30\"]\n",
    "output_format = \"gtiff\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "53d0800c-a6b3-4a64-a7a2-f27689adc7d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map related settings\n",
    "center = shape(spatial_extent).centroid\n",
    "zoom = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67aa06f1-b821-41e6-abe1-b40fbc6ca2ac",
   "metadata": {},
   "source": [
    "## Authentication with the API\n",
    "To access the different endpoints of the Dispatcher API it is important to first authenticate yourself with the APEx environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "47c7fe82-b611-404c-9cb8-204497dbec57",
   "metadata": {},
   "outputs": [],
   "source": [
    "KEYCLOAK_HOST = \"auth.dev.apex.esa.int\"\n",
    "CLIENT_ID = \"apex-dispatcher-api-dev\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b5ee27f5-9e69-4557-ba83-ec7cb74aa874",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Endpoints\n",
    "authorization_endpoint = f\"https://{KEYCLOAK_HOST}/realms/apex/protocol/openid-connect/auth\"\n",
    "token_endpoint = f\"https://{KEYCLOAK_HOST}/realms/apex/protocol/openid-connect/token\"\n",
    "\n",
    "# Global token store\n",
    "_token_data = None\n",
    "\n",
    "def get_access_token():\n",
    "    \"\"\"\n",
    "    Returns a valid access token. Refreshes it automatically if expired.\n",
    "    \"\"\"\n",
    "    global _token_data\n",
    "\n",
    "    # If we have a token and it hasn't expired yet, return it\n",
    "    if _token_data and _token_data.get(\"expires_at\", 0) > time.time() + 10:\n",
    "        return _token_data[\"access_token\"]\n",
    "\n",
    "    # If token exists but is expired and has a refresh_token, refresh it\n",
    "    if _token_data and \"refresh_token\" in _token_data:\n",
    "        session = OAuth2Session(CLIENT_ID, token=_token_data)\n",
    "        _token_data = session.refresh_token(token_endpoint)\n",
    "        return _token_data[\"access_token\"]\n",
    "\n",
    "    # Otherwise, start a new OAuth2 flow\n",
    "    session = OAuth2Session(\n",
    "        client_id=CLIENT_ID,\n",
    "        redirect_uri=\"http://localhost:8000/callback\"\n",
    "    )\n",
    "    uri, state = session.create_authorization_url(authorization_endpoint)\n",
    "    print(\"Open this URL in your browser:\", uri)\n",
    "    redirect_url = input(\"Paste the redirect URL here: \")\n",
    "    parsed = urlparse(redirect_url)\n",
    "    code = parse_qs(parsed.query).get(\"code\")[0]\n",
    "\n",
    "    _token_data = session.fetch_token(\n",
    "        token_endpoint,\n",
    "        code=code,\n",
    "        client_secret=None,  # only if your client is confidential\n",
    "        include_client_id=True\n",
    "    )\n",
    "\n",
    "    return _token_data[\"access_token\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33c539b8-51e3-43a5-b88e-bc2ac0f89c43",
   "metadata": {},
   "source": [
    "## Retrieval of the tiles\n",
    "The first step in our upscaling exercise is to determine the different tiles to be processed based on the given `area_of_interest`. In this example we ask the dispatcher to split up the area in a `20x20km` grid. This results in a list of tiles that are visualised on the map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e0618338",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 9 tiles for area of interest\n"
     ]
    }
   ],
   "source": [
    "tiles = requests.post(f\"http://{dispatch_api}/tiles\", json={\n",
    "    \"grid\": \"20x20km\",\n",
    "    \"aoi\": spatial_extent\n",
    "}).json()\n",
    "print(f\"Processing {len(tiles['geometries'])} tiles for area of interest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6de8d686",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68d472f3512f4321bdfe6286c0eb8029",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map(center=[48.201908597505785, 16.387852714727558], controls=(ZoomControl(options=['position', 'zoom_in_text'…"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a map centered at the approximate center of the area of interest\n",
    "m = Map(center=[center.y, center.x], zoom=zoom)\n",
    " \n",
    "# Add the tiles (GeometryCollection) to the map\n",
    "geo_json = GeoJSON(data=tiles)\n",
    "m.add_layer(geo_json)\n",
    "\n",
    "# Display the map\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b79dc3d-7734-4e30-86d8-b1868f5f170a",
   "metadata": {},
   "source": [
    "## Launching the upscaling task\n",
    "\n",
    "Next we trigger the upscaling task on the dispatcher. We provide the details of the processing jobs that need to be executed together with a `dimension`. This is an important parameter as this lets the dispatcher know how to scale up. In this case we are asking the dispatcher to scale up using the `spatial_extent`, creating a separate job for each geometry in the `values` section. The dispatcher will take care of all the rest. The result is the information on the created upscaling task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c5ca3fdd-7559-4fc7-8318-61b5dc59475f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 14,\n",
       " 'title': 'Upscalinge - PV Detection',\n",
       " 'label': 'openeo',\n",
       " 'status': 'created'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "upscaling_task = requests.post(\n",
    "    f\"http://{dispatch_api}/upscale_tasks\", \n",
    "    headers={\n",
    "        \"Authorization\": f\"Bearer {get_access_token()}\"        \n",
    "    },\n",
    "    json={\n",
    "        \"title\": \"Upscalinge - PV Detection\",\n",
    "        \"label\": \"openeo\",\n",
    "        \"service\": {\n",
    "            \"endpoint\": service.service_links[0].href,\n",
    "            \"application\": service.udp_link.href\n",
    "        },\n",
    "        \"format\": output_format,\n",
    "        \"parameters\": {\n",
    "            \"temporal_extent\": temporal_extent\n",
    "        },\n",
    "        \"dimension\": {\n",
    "            \"name\": \"spatial_extent\",\n",
    "            \"values\": tiles[\"geometries\"]\n",
    "        }\n",
    "    }\n",
    ").json()\n",
    "upscaling_task_id = upscaling_task['id']\n",
    "upscaling_task"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38adee61-7fb3-49c7-88cc-063009819a37",
   "metadata": {},
   "source": [
    "## Retrieve status of the upscaling task\n",
    "We can now write a continuous monitoring process that fetches the status of the upscaling task and showcase the results on the map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "02e5c413-d110-4110-be59-c86e5226edc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_cog_layer(cog_url, name=None, m=m):\n",
    "    with rasterio.open(cog_url) as src:\n",
    "        band = src.read(1).astype(np.float32)\n",
    "\n",
    "        bounds = transform_bounds(src.crs, \"EPSG:4326\", *src.bounds)\n",
    "\n",
    "        # Normalize 0–255\n",
    "        band = 255 * (band - band.min()) / (band.max() - band.min())\n",
    "        band = band.astype(np.uint8)\n",
    "\n",
    "    # Convert to PNG data URI\n",
    "    buf = io.BytesIO()\n",
    "    Image.fromarray(band).save(buf, format=\"PNG\")\n",
    "    data_url = \"data:image/png;base64,\" + base64.b64encode(buf.getvalue()).decode(\"utf-8\")\n",
    "\n",
    "    bbox = ((bounds[1], bounds[0]), (bounds[3], bounds[2]))\n",
    "    overlay = ImageOverlay(url=data_url, bounds=bbox, name=name or \"Gray COG\")\n",
    "    m.add_layer(overlay)\n",
    "    return overlay\n",
    "\n",
    "def add_geojson_layer(url,name=None, m=m):\n",
    "    data = requests.get(url).json()\n",
    "    transformer = Transformer.from_crs(data[\"crs\"][\"properties\"][\"name\"], \"EPSG:4326\", always_xy=True)\n",
    "\n",
    "    for feature in data[\"features\"]:\n",
    "        geom = feature[\"geometry\"]\n",
    "        if geom[\"type\"] == \"Polygon\":\n",
    "            new_coords = []\n",
    "            for ring in geom[\"coordinates\"]:\n",
    "                new_ring = [transformer.transform(x, y) for x, y in ring]\n",
    "                new_coords.append(new_ring)\n",
    "            geom[\"coordinates\"] = new_coords\n",
    "    geo_json = GeoJSON(data=data)\n",
    "    m.add_layer(geo_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ac428293-7cd4-49a8-9bfa-4e0dc8f4d2cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a48eeee1172342cf8fa7a6efab0a660a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map(center=[48.201908597505785, 16.387852714727558], controls=(ZoomControl(options=['position', 'zoom_in_text'…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job finished with status finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/50/09_2zmx12zj6ks4fdl4y9wgc0000gn/T/ipykernel_65314/627856076.py:81: RuntimeWarning: coroutine 'Connection.close' was never awaited\n",
      "  websocket.close()\n",
      "RuntimeWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    }
   ],
   "source": [
    "# Function to style jobs\n",
    "def job_style(feature):\n",
    "    status = feature[\"properties\"][\"status\"]\n",
    "    color = {\n",
    "        \"created\": \"blue\",\n",
    "        \"queued\": \"orange\",\n",
    "        \"running\": \"yellow\",\n",
    "        \"finished\": \"green\",\n",
    "        \"canceled\": \"gray\",\n",
    "        \"failed\": \"red\"\n",
    "    }.get(feature[\"properties\"][\"status\"], \"black\")\n",
    "    return {\n",
    "        \"color\": color,\n",
    "        \"fillColor\": color,\n",
    "        \"fillOpacity\": 0.5 if status != \"finished\" else 0.0\n",
    "    }\n",
    "\n",
    "\n",
    "m = Map(center=[center.y, center.x], zoom=zoom)\n",
    "geo_json = GeoJSON(\n",
    "    data={\n",
    "        \"type\": \"FeatureCollection\",\n",
    "        \"features\": []\n",
    "    }\n",
    ")\n",
    "geo_json.style_callback = job_style\n",
    "m.add_layer(geo_json)\n",
    "m.layout.height = '1000px'\n",
    "display(m)\n",
    "\n",
    "\n",
    "# Keep track of processed jobs\n",
    "processed_jobs = set()\n",
    "\n",
    "async def show_results(job_id):\n",
    "    async with httpx.AsyncClient() as client:\n",
    "        result = await client.get(f\"http://{dispatch_api}/unit_jobs/{job_id}/results\", headers={\n",
    "            \"Authorization\": f\"Bearer {get_access_token()}\"\n",
    "        })\n",
    "        response = result.json()\n",
    "        if output_format.lower() == \"geojson\":\n",
    "            result = response[\"assets\"][\"vectorcube.geojson\"][\"href\"]\n",
    "            add_geojson_layer(result, name=f\"Job {job_id}\", m=m)\n",
    "        else:\n",
    "            cog = response[\"assets\"][\"openEO.tif\"][\"href\"]\n",
    "            add_cog_layer(cog, name=f\"Job {job_id}\", m=m)\n",
    "        return response\n",
    "\n",
    "async def listen_for_updates():\n",
    "    ws_url = f\"ws://{dispatch_api}/ws/upscale_tasks/{upscaling_task_id}?interval=15&token={get_access_token()}\"\n",
    "    async with websockets.connect(ws_url) as websocket:\n",
    "        while True:\n",
    "            message = await websocket.recv()\n",
    "            message = json.loads(message)\n",
    "            if message.get(\"data\"):\n",
    "                features = []\n",
    "                for job in message[\"data\"][\"jobs\"]:\n",
    "                    job_id = job[\"id\"]\n",
    "                    job_status = job[\"status\"]\n",
    "\n",
    "                    features.append({\n",
    "                        \"type\": \"Feature\",\n",
    "                        \"geometry\": job[\"parameters\"][\"spatial_extent\"],\n",
    "                        \"properties\": {\n",
    "                            \"status\": job_status,\n",
    "                        }\n",
    "                    })\n",
    "                    \n",
    "                    # If the job is finished and not yet processed, fetch results\n",
    "                    if job_status == \"finished\" and job_id not in processed_jobs:\n",
    "                        processed_jobs.add(job_id)\n",
    "                        await show_results(job_id)\n",
    "         \n",
    "                    geo_json.data = {\n",
    "                        \"type\": \"FeatureCollection\",\n",
    "                        \"features\": features\n",
    "                    }\n",
    "                \n",
    "                if message[\"data\"][\"status\"] in [\"finished\", \"canceled\", \"failed\"]:\n",
    "                    print(f\"Job finished with status {message['data']['status']}\")\n",
    "                    websocket.close()\n",
    "                    break\n",
    "\n",
    "# Run the websocket listener in the notebook\n",
    "await listen_for_updates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "969de642-1d95-44be-9f51-1c326641d5a8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
